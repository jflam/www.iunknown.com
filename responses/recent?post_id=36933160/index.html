{"post_id":36933160,"html":"\u003Cdiv class='p_response_container' style='display:none;'\u003E\n\u003Cheader class='clearfix'\u003E\n\u003Ca href=\"http://iunknown.com/2006/05/rubyclr-can-make-activerecord-much-much-faster.html\" class=\"p_view_all_link\"\u003EView All 5\u003C/a\u003E\n\u003Ch1\u003EMost Recent Responses\u003C/h1\u003E\n\u003C/header\u003E\n\u003Cdiv class='p_responses_list clearfix' data-posterous-responses-container\u003E\n\u003Carticle class='p_comment p_response' style='display:none;'\u003E\n\u003Cdiv class='p_info'\u003E\n\u003Cspan class='p_icon'\u003E\u003C/span\u003E\n\u003Ctime pubdate='1147452556'\u003Eabout 7 years ago\u003C/time\u003E\nJohn Lam responded:\n\u003C/div\u003E\n\u003Cdiv class='p_comment_body'\u003E\n\u003Cdiv class='p_profile_photo'\u003E\n\u003Cimg alt=\"\" src=\"/images/profile/missing-user-35.png?1367517938\" /\u003E\n\u003C/div\u003E\n\u003Cdiv class='p_comment_text'\u003E\nIt's now faster, now just a 3X slowdown over DataSets. The reality is that for most client-side applications, this perf difference just doesn't matter. After all, we're retrieving 20,000 records (and from a local DB - network latency + server load would decrease the perf advantage of DataSets).\n\u003C/div\u003E\n\u003C/div\u003E\n\u003Cul class='p_action_links'\u003E\n\u003C/ul\u003E\n\n\u003C/article\u003E\n\n\u003Carticle class='p_comment p_response' style='display:none;'\u003E\n\u003Cdiv class='p_info'\u003E\n\u003Cspan class='p_icon'\u003E\u003C/span\u003E\n\u003Ctime pubdate='1147636008'\u003Eabout 7 years ago\u003C/time\u003E\nAmr responded:\n\u003C/div\u003E\n\u003Cdiv class='p_comment_body'\u003E\n\u003Cdiv class='p_profile_photo'\u003E\n\u003Cimg alt=\"\" src=\"/images/profile/missing-user-35.png?1367517938\" /\u003E\n\u003C/div\u003E\n\u003Cdiv class='p_comment_text'\u003E\nis find_by_sql as fast as this technique? Personally I would always want to get to a point (by optimizing the search condition beforehand )where I don't have to get 20,000 records in the client before I can process the retrieved dataset.\u003Cbr /\u003EI would hate to work with million row tables if the main option was to load the whole dataset on the client side first.\n\u003C/div\u003E\n\u003C/div\u003E\n\u003Cul class='p_action_links'\u003E\n\u003C/ul\u003E\n\n\u003C/article\u003E\n\n\u003Carticle class='p_comment p_response' style='display:none;'\u003E\n\u003Cdiv class='p_info'\u003E\n\u003Cspan class='p_icon'\u003E\u003C/span\u003E\n\u003Ctime pubdate='1147639111'\u003Eabout 7 years ago\u003C/time\u003E\nJohn Lam responded:\n\u003C/div\u003E\n\u003Cdiv class='p_comment_body'\u003E\n\u003Cdiv class='p_profile_photo'\u003E\n\u003Cimg alt=\"\" src=\"/images/profile/missing-user-35.png?1367517938\" /\u003E\n\u003C/div\u003E\n\u003Cdiv class='p_comment_text'\u003E\nThe rate-limiting step in all of this is loading the data into the array of hashtables. So it will affect things regardless of whether you use find_by_sql or the dynamic finders. I'm just using find_all here to retrieve a large set of data that I can do some perf tuning on.\u003Cbr /\u003EI'm by no way advocating reading 20,000 row data sets to do client side processing - I just look at this as  an interesting performance test to see whether I can improve the performance of ActiveRecord when talking to SQL Server.\n\u003C/div\u003E\n\u003C/div\u003E\n\u003Cul class='p_action_links'\u003E\n\u003C/ul\u003E\n\n\u003C/article\u003E\n\n\u003C/div\u003E\n\u003Cdiv class='p_comment_form p_logged_in'\u003E\n\u003Ch1\u003ELeave a Comment\u003C/h1\u003E\n\u003Cform action=\"/responses/create\" class=\"new_comment clearfix\" id=\"new_comment\" method=\"post\"\u003E\u003Cdiv style=\"margin:0;padding:0;display:inline\"\u003E\u003Cinput name=\"authenticity_token\" type=\"hidden\" value=\"K5qluXl5HOIU9bWdq9oJYrEuVokj7nLG7aYeXTLdHqg=\" /\u003E\u003C/div\u003E\n\u003Cdiv class='p_not_authorized p_comment_section'\u003E\n\u003Cdiv class='p_additional_fields'\u003E\n\u003Clabel for=\"comment_name\"\u003EName:\u003C/label\u003E\n\u003Cinput id=\"comment_name\" maxlength=\"80\" name=\"comment[name]\" size=\"40\" type=\"text\" /\u003E\n\u003Clabel class=\"p_comment_email\" for=\"comment_comment_email\"\u003ELeave this field blank to comment.\u003C/label\u003E\n\u003Cinput class=\"p_comment_email\" id=\"comment_comment_email\" maxlength=\"80\" name=\"comment[comment_email]\" size=\"40\" type=\"text\" /\u003E\n\u003Clabel for=\"comment_toast\"\u003EEmail:\u003C/label\u003E\n\u003Cinput id=\"comment_toast\" maxlength=\"80\" name=\"comment[toast]\" size=\"40\" type=\"text\" /\u003E\n\u003Clabel for=\"comment_url\"\u003EHomepage:\u003C/label\u003E\n\u003Cinput id=\"comment_url\" maxlength=\"80\" name=\"comment[url]\" size=\"40\" type=\"text\" /\u003E\n\u003C/div\u003E\n\u003Caside class='p_login_options'\u003E\n\u003Cdiv class='p_asterisk'\u003E\u003C/div\u003E\n\u003Ch1\u003EWant to skip this stuff?\u003C/h1\u003E\n\u003Cp\u003ELogin with any of the following:\u003C/p\u003E\n\u003Cdiv class='p_login_buttons'\u003E\n\u003Ca href=\"http://posterous.com/login?flow=newcomment\u0026amp;jumpto=http%3A%2F%2Fiunknown.com%2F2006%2F05%2Frubyclr-can-make-activerecord-much-much-faster.html%23comment\" class=\"p_posterous_login\"\u003ERegister or login to Posterous\u003C/a\u003E\n\u003Ca href=\"#\" class=\"p_twitter_login\" data-posterous-jumpto-url=\"http://iunknown.com/2006/05/rubyclr-can-make-activerecord-much-much-faster.html#comment\" data-posterous-post-id=\"36933160\" data-posterous-redirect-url=\"http://posterous.com/oauth/init_oauth_and_redirect/?ssod=iunknown.com\u0026amp;oauth_provider_type=\" data-posterous-twitter-login-button=\"true\"\u003E\u003Cimg alt=\"Sign in with Twitter\" src=\"/images/site/sign_in_with_twitter.png?1367517938\" /\u003E\u003C/a\u003E\n\u003C/div\u003E\n\n\u003C/aside\u003E\n\u003C/div\u003E\n\u003Cdiv class='p_comment_section'\u003E\n\u003Clabel for=\"comment_body\"\u003EComment:\u003C/label\u003E\n\u003Cdiv class='p_comment_area'\u003E\n\u003Ctextarea cols=\"40\" id=\"comment_body\" name=\"comment[body]\" onChange=\"if (this.scrollHeight \u0026gt; this.clientHeight \u0026amp;\u0026amp; !window.opera){this.rows += 1;}\" onKeyPress=\"if (this.scrollHeight \u0026gt; this.clientHeight \u0026amp;\u0026amp; !window.opera){this.rows += 1;}\" rows=\"5\"\u003E\u003C/textarea\u003E\n\u003C/div\u003E\n\u003C/div\u003E\n\u003Cdiv class='p_comment_section'\u003E\n\u003Cinput id=\"comment_post_id\" name=\"comment[post_id]\" type=\"hidden\" value=\"36933160\" /\u003E\n\u003Cdiv class='p_submit'\u003E\u003Cbutton button=\"true\" class=\" action_button\"\u003E\u003Cspan class=\"\"\u003EPost this Comment\u003C/span\u003E\u003C/button\u003E\u003C/div\u003E\n\u003C/div\u003E\n\u003C/form\u003E\n\u003C/div\u003E\n\n\u003C/div\u003E\n","responses":[{"name":"John Lam","body_html":"It's now faster, now just a 3X slowdown over DataSets. The reality is that for most client-side applications, this perf difference just doesn't matter. After all, we're retrieving 20,000 records (and from a local DB - network latency + server load would decrease the perf advantage of DataSets).","created_at":"2006/05/12 09:49:16 -0700","body":"It's now faster, now just a 3X slowdown over DataSets. The reality is that for most client-side applications, this perf difference just doesn't matter. After all, we're retrieving 20,000 records (and from a local DB - network latency + server load would decrease the perf advantage of DataSets).\n","post_id":36933160,"id":6478137,"display_name":"John Lam","comment_type":"comment","display_url":null,"allowed":true,"display_photo":"/images/profile/missing-user-35.png"},{"name":"Amr","body_html":"is find_by_sql as fast as this technique? Personally I would always want to get to a point (by optimizing the search condition beforehand )where I don't have to get 20,000 records in the client before I can process the retrieved dataset.\u003Cbr /\u003EI would hate to work with million row tables if the main option was to load the whole dataset on the client side first.","created_at":"2006/05/14 12:46:48 -0700","body":"is find_by_sql as fast as this technique? Personally I would always want to get to a point (by optimizing the search condition beforehand )where I don't have to get 20,000 records in the client before I can process the retrieved dataset.\nI would hate to work with million row tables if the main option was to load the whole dataset on the client side first.\n","post_id":36933160,"id":6478138,"display_name":"Amr","comment_type":"comment","display_url":null,"allowed":true,"display_photo":"/images/profile/missing-user-35.png"},{"name":"John Lam","body_html":"The rate-limiting step in all of this is loading the data into the array of hashtables. So it will affect things regardless of whether you use find_by_sql or the dynamic finders. I'm just using find_all here to retrieve a large set of data that I can do some perf tuning on.\u003Cbr /\u003EI'm by no way advocating reading 20,000 row data sets to do client side processing - I just look at this as  an interesting performance test to see whether I can improve the performance of ActiveRecord when talking to SQL Server.","created_at":"2006/05/14 13:38:31 -0700","body":"The rate-limiting step in all of this is loading the data into the array of hashtables. So it will affect things regardless of whether you use find_by_sql or the dynamic finders. I'm just using find_all here to retrieve a large set of data that I can do some perf tuning on.\nI'm by no way advocating reading 20,000 row data sets to do client side processing - I just look at this as  an interesting performance test to see whether I can improve the performance of ActiveRecord when talking to SQL Server.\n","post_id":36933160,"id":6478139,"display_name":"John Lam","comment_type":"comment","display_url":null,"allowed":true,"display_photo":"/images/profile/missing-user-35.png"}]}